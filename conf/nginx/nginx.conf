daemon off;
pid /var/lib/hypothesis/nginx.pid;
error_log /dev/stderr;
worker_rlimit_nofile 7192;

events {
    worker_connections  1024;
}

http {
    include       mime.types;
    default_type  application/octet-stream;
    sendfile        on;
    keepalive_timeout  65;
    resolver 8.8.8.8 ipv6=off;
    access_log /dev/stdout;

    # The AWS load balancer talks to the server via http so use the scheme the
    # client provided in the originating request via AWS's X-Forwarded-Proto
    # header. If it does not exist, fallback to $scheme.
    map $http_x_forwarded_proto $original_scheme {
        "" $scheme;
        default $http_x_forwarded_proto;
    }

    # We set fail_timeout=0 so that the upstream isn"t marked as down if a single
    # request fails (e.g. if gunicorn kills a worker for taking too long to handle
    # a single request).
    upstream web {
        include via/app_upstream.conf;
    }

    server {
        include /var/lib/hypothesis/nginx_envsubst.conf;
        listen 9083;
        merge_slashes off;

        location ~ /proxy/static/ {
            proxy_intercept_errors on;
            error_page 301 302 307 = @handle_redirect;

            # Handle most errors upstream listed at:
            # https://www.restapitutorial.com/httpstatuscodes.html
            error_page 404 410 = @proxy_not_found;
            error_page 420 429 = @proxy_too_many_requests;
            error_page 400 401 402 403 405 406 407 408 409 411 412 413 414 415 416 417 418 422 423 424 425 426 428 431 444 449 450 451 = @proxy_client_error;
            error_page 500 501 502 503 504 505 506 507 508 509 510 511 598 599 = @proxy_upstream_error;

            include via/direct_proxy.conf;

            # Cache for a 1 day, but allow serving from cache while revalidating for a week
            proxy_hide_header "Cache-Control";
            add_header "Cache-Control" "public, max-age=86400, stale-while-revalidate=604800";

            add_header "X-Via" "static-proxy, direct";
        }

        location @handle_redirect {
            include via/direct_proxy.conf;

            # Disable caching to prevent Cloudflare from kicking in where this
            # might be a temporary redirect to an expiring PDF link
            proxy_hide_header "Cache-Control";
            add_header "Cache-Control" "no-cache, no-store, must-revalidate";

            add_header "X-Via" "static-proxy, redirect";
        }

        location @proxy_not_found {
            # Not found / gone => 404 not found
            try_files /proxy/not_found.html =404;
        }

        location @proxy_too_many_requests {
            # Too many requests => 429 too many requests
            try_files /proxy/too_many_requests.html =429;
        }

        location @proxy_client_error {
            # All other 40x -> 400 bad request
            try_files /proxy/client_error.html =400;
        }

        location @proxy_upstream_error {
            # All 50x -> 409 -> 409 conflict (with state of resource)
            try_files /proxy/upstream_error.html =409;
        }

        location / {
            proxy_pass http://web;
            proxy_http_version 1.1;

            proxy_connect_timeout 10s;
            proxy_send_timeout 10s;
            # This is how long we will wait for a response from the service
            # This has to be longer than the time we wait for websites to
            # allow us to handle timeouts inside the app
            proxy_read_timeout 20s;

            proxy_redirect off;

            proxy_set_header Host $http_host;
            proxy_set_header X-Forwarded-Server $http_host;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Request-Start "t=${msec}";

            add_header "X-Via" "compute";
        }
    }
}
